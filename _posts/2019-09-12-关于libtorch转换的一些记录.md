---
layout:     post   				    # 使用的布局（不需要改）
title:      关于libtorch转换的一些记录 				# 标题 
date:       2019-09-12 				# 时间
header-img: img/post-bg-2015.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - CornerNet-Lite
    - libtorch
---

---

在使用CornerNet-Lite训练完成之后，想要使用libtorch进行部署，因此需要将CornerNet-Lite的inference进行一定的修改，然后导出为libtorch可以使用的模型文件。

---

## 关于CornerNet-Lite的inference导出

- 因为libtorch的输出只能是单个的tensor，所以需要将最后的输出使用torch.cat函数进行一个拼接，在libtorch中使用的时候，在用torch.split函数进行分割，注意需要记录下合并的tensor的各个维度

- 由于CornerNet-Lite中使用了一部分c++实现的op，因此在转换之前，需要将c++实现的op重新采用自定义op的形式生成so文件，然后修改源代码，直接使用torch.ops.load_library函数来进行加载，并且替换Python网络中的top_pool、bottom_pool、right_pool以及left_pool

- CornerNet-Lite的整体网络框架只能到decode函数之前，后续的操作，需要在转为c++之后，使用libtorch进行处理，包括bbox的边框的处理，nms的处理等

- CornerNet-Lite的inference中的网络在train和test时是不同的，目前转换没有考虑到这些，这些网络在inference的时候，可能会占用一定的运行时间，导致运行时间变慢，而且会导致模型没有办法减小，后续会对这个进行考虑。

- 在使用NMS时候，发现使用soft-nms特别慢，因此采用了nms的策略，速度提升很多。不过精度确实有部分下降，后续要把soft-nms实现了。

## 关于libtorch的使用

- 在使用libtorch时，**一定要使用官网提供的版本，而且一定要和你训练用的版本对应**，否则可能会出现问题

- 使用cmake进行库或者程序编译时，一定注意**target_compile_features(excutename PRIVATE cxx_range_for)**这句的设置，否则可能会出现问题

- 在生成库的时候，包括上节的第二个点，**一定不要用你的Python安装的torch，一定使用从官网下载的libtorch的版本**，否则会出现实际部署依赖项时，出现很多的依赖项，并且可能会无法部署

## UPDATE

### 2019年09月17日

- 调整了参数后，目前libtorch与python的精度与速度一致

## 后记

这个转换的libtorch版本，后期可能会开源，如果有需要可以联系我。
